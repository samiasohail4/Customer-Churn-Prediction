{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1aecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Make sure the filename is correct (case-sensitive!)\n",
    "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\")\n",
    "\n",
    "# Preview the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7a6738",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed8ffbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TotalCharges to float, coercing bad data to NaN\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513477dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TotalCharges'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db20476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where TotalCharges couldn't be converted\n",
    "df = df.dropna(subset=['TotalCharges'])\n",
    "\n",
    "# Convert SeniorCitizen to Yes/No\n",
    "df['SeniorCitizen'] = df['SeniorCitizen'].replace({1: 'Yes', 0: 'No'})\n",
    "\n",
    "# Drop customerID (not useful for analysis)\n",
    "df.drop('customerID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471ba72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'SeniorCitizen'] = df['SeniorCitizen'].replace({1: 'Yes', 0: 'No'})\n",
    "df = df.drop('customerID', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd32cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1b8330",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Churn'].value_counts()\n",
    "df['Churn'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294e82d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.countplot(x='Churn', data=df)\n",
    "plt.title('Customer Churn Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8d7637",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='gender', hue='Churn', data=df)\n",
    "plt.title('Churn by Gender')\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x='Contract', hue='Churn', data=df)\n",
    "plt.title('Churn by Contract Type')\n",
    "plt.show()\n",
    "\n",
    "sns.countplot(x='InternetService', hue='Churn', data=df)\n",
    "plt.title('Churn by Internet Service')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6057786",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x='Churn', y='tenure', data=df)\n",
    "plt.title('Tenure vs Churn')\n",
    "plt.show()\n",
    "\n",
    "sns.boxplot(x='Churn', y='MonthlyCharges', data=df)\n",
    "plt.title('Monthly Charges vs Churn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ba7e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Contract', hue='Churn', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5808c684",
   "metadata": {},
   "source": [
    "## 📊 Exploratory Data Analysis Summary: Customer Churn\n",
    "\n",
    "We performed exploratory data analysis to understand the patterns behind customer churn in a telecom company. Below are key findings from visualizations:\n",
    "\n",
    "- **Contract Type**: Customers on **month-to-month** contracts have the highest churn rate, while those on one- or two-year contracts are far less likely to leave. This is one of the most significant drivers of churn.\n",
    "- **Tenure**: Customers with **shorter tenure** are significantly more likely to churn. The longer a customer stays, the less likely they are to leave.\n",
    "- **Monthly Charges**: Customers who churn tend to have **higher monthly charges**, suggesting that price sensitivity could be contributing to churn.\n",
    "- **Internet Service Type**: Customers using **fiber optic** internet service churn more than DSL or those without internet. This may relate to pricing, satisfaction, or service reliability.\n",
    "- **Gender**: No notable difference in churn rates between male and female customers. This feature may not provide predictive value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6318380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Encode binary categorical columns (like 'Yes'/'No')\n",
    "binary_cols = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn']\n",
    "for col in binary_cols:\n",
    "    if df[col].dtype == 'object':\n",
    "        df[col] = df[col].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# 3. Convert SeniorCitizen from object to int safely\n",
    "df['SeniorCitizen'] = pd.to_numeric(df['SeniorCitizen'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# 4. One-hot encode multi-category columns (only if not already done)\n",
    "multi_cat_cols = ['InternetService', 'Contract', 'PaymentMethod', 'MultipleLines',\n",
    "                  'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "                  'StreamingTV', 'StreamingMovies', 'gender']\n",
    "\n",
    "existing_multi_cat_cols = [col for col in multi_cat_cols if col in df.columns]\n",
    "df = pd.get_dummies(df, columns=existing_multi_cat_cols, drop_first=True)\n",
    "\n",
    "# 5. Drop target column and split into features/target\n",
    "X = df.drop('Churn', axis=1)\n",
    "y = df['Churn']\n",
    "\n",
    "# 6. Output checks\n",
    "print(\"\\n✅ Preprocessing complete!\")\n",
    "print(\"Shape of features (X):\", X.shape)\n",
    "print(\"Shape of target (y):\", y.shape)\n",
    "print(\"\\nFirst 5 rows of processed features:\")\n",
    "print(X.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929bd65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405190bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa0c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = ['Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'Churn']\n",
    "for col in binary_cols:\n",
    "    if col in df.columns and df[col].notna().sum() > 0:\n",
    "        df[col] = df[col].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0ae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca81a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f2585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7698f76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Create an imputer that replaces missing values with the column mean (good for numeric columns)\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit the imputer on the training data and transform both training and test sets\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a63c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Separate numerical and categorical columns\n",
    "numeric_features = ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
    "categorical_features = ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'PhoneService', 'PaperlessBilling', 'InternetService', 'Contract', 'PaymentMethod']\n",
    "\n",
    "# Define transformers\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean'))\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# Final pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581f311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c13216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv(\"your_data.csv\")\n",
    "\n",
    "# --------------------------\n",
    "# 🛠️ Fix 1: Convert boolean columns to string or integer\n",
    "bool_cols = df.select_dtypes(include='bool').columns\n",
    "df[bool_cols] = df[bool_cols].astype(str)  # or use astype(int) if preferred\n",
    "\n",
    "# 🛠️ Fix 2: Drop columns that are entirely NaN\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# --------------------------\n",
    "# Split the data\n",
    "X = df.drop(\"target_column\", axis=1)  # replace with your actual target column name\n",
    "y = df[\"target_column\"]\n",
    "\n",
    "# Ensure X is a DataFrame when splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# --------------------------\n",
    "# Define column types\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# --------------------------\n",
    "# Preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "])\n",
    "\n",
    "# --------------------------\n",
    "# Final pipeline with classifier\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# --------------------------\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Done! 🎉 You can now predict, score, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d242f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 1. Load your data\n",
    "df = pd.read_csv(\"WA_Fn-UseC_-Telco-Customer-Churn.csv\") \n",
    "\n",
    "# 2. Clean boolean columns (convert to int)\n",
    "bool_cols = df.select_dtypes(include='bool').columns\n",
    "df[bool_cols] = df[bool_cols].astype(int)\n",
    "\n",
    "# 3. Drop columns with all missing values\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# 4. Separate features and target\n",
    "X = df.drop(\"Churn\", axis=1)  # Replace with your actual target column name\n",
    "y = df[\"Churn\"]\n",
    "\n",
    "# 5. Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Select column types\n",
    "num_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# 7. Preprocessing pipelines\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# 8. Combine preprocessors\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, num_cols),\n",
    "    ('cat', categorical_transformer, cat_cols)\n",
    "])\n",
    "\n",
    "# 9. Full pipeline with Logistic Regression\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# 10. Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 11. Evaluate\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df9bf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Churn', 'Churn'], yticklabels=['No Churn', 'Churn'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba9a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb431b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "y_pred_proba = model.predict_proba(X_test)[::,1]\n",
    "\n",
    "# Compute ROC values\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Plot ROC\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc_score(y_test, y_pred_proba):.2f}\")\n",
    "plt.plot([0,1], [0,1], linestyle='--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb0e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert target values to 0 (No) and 1 (Yes)\n",
    "y_train = y_train.map({'No': 0, 'Yes': 1})\n",
    "y_test = y_test.map({'No': 0, 'Yes': 1})\n",
    "# Compute ROC values\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Plot ROC\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc_score(y_test, y_pred_proba):.2f}\")\n",
    "plt.plot([0,1], [0,1], linestyle='--', color='gray')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85448e6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
